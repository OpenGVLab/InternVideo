2024-02-26T15:51:07 | INFO | vindlu : Logging to: exp/exp_pretrain_videoclip/viclip_base/viclip_base/train.log
2024-02-26T15:51:07 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: VindLU_VideoCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_videoclip/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 2
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-26T15:51:07 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-26T15:51:07 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2024-02-26T15:51:07 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-26T15:51:07 | INFO | __main__ : Creating dataset for pt
2024-02-26T15:51:07 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-26T15:52:29 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-26T15:52:29 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-26T15:53:05 | INFO | tasks.shared_utils : Creating model
2024-02-26T16:11:57 | INFO | vindlu : Logging to: exp/exp_pretrain_videoclip/viclip_base/viclip_base/train.log
2024-02-26T16:11:57 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: VindLU_VideoCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_videoclip/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 2
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-26T16:11:57 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-26T16:11:57 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2024-02-26T16:11:57 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-26T16:11:57 | INFO | __main__ : Creating dataset for pt
2024-02-26T16:11:57 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-26T16:13:15 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-26T16:13:16 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-26T16:13:51 | INFO | tasks.shared_utils : Creating model
2024-02-26T16:13:51 | INFO | models.vindlu_videoclip : vision encoder name: vit_b16
2024-02-26T16:13:52 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-26T16:13:53 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-26T16:13:53 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-26T16:13:53 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-26T16:13:53 | INFO | models.vindlu_videoclip : text encoder name: vit_b16
2024-02-26T16:13:53 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-26T16:13:55 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-26T16:13:55 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-26T16:13:55 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-26T16:13:55 | INFO | tasks.shared_utils : Auto resuming
2024-02-26T16:13:55 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_videoclip/viclip_base/viclip_base
2024-02-26T16:13:55 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-26T16:13:55 | INFO | __main__ : Start training
2024-02-26T16:13:58 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 10397 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=10397 
2024-02-26T16:16:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:16:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:25:29 | INFO | vindlu : Logging to: exp/exp_pretrain_videoclip/viclip_base/viclip_base/train.log
2024-02-26T16:25:29 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: VindLU_VideoCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_videoclip/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 2
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-26T16:25:29 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-26T16:25:29 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 2 nodes.
2024-02-26T16:25:29 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-26T16:25:29 | INFO | __main__ : Creating dataset for pt
2024-02-26T16:25:29 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-26T16:26:50 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-26T16:26:51 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-26T16:27:30 | INFO | tasks.shared_utils : Creating model
2024-02-26T16:27:30 | INFO | models.vindlu_videoclip : vision encoder name: vit_b16
2024-02-26T16:27:31 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-26T16:27:32 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-26T16:27:32 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-26T16:27:32 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-26T16:27:32 | INFO | models.vindlu_videoclip : text encoder name: vit_b16
2024-02-26T16:27:32 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-26T16:27:33 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-26T16:27:33 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-26T16:27:33 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-26T16:27:33 | INFO | tasks.shared_utils : Auto resuming
2024-02-26T16:27:33 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_videoclip/viclip_base/viclip_base
2024-02-26T16:27:33 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-26T16:27:33 | INFO | __main__ : Start training
2024-02-26T16:27:37 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 10397 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=10397 
2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:31:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-26T16:47:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-26T16:47:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-26T16:47:23 | INFO | utils.basic_utils : Train Epoch: [0]  [    0/10397]  eta: 142 days, 17:38:27  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 4.4972  time: 1186.1410  data: 1168.4843  max mem: 41900 res mem: 46636
2024-02-26T16:47:23 | INFO | torch.nn.parallel.distributed : Reducer buckets have been rebuilt in this iteration.
2024-02-26T17:01:58 | INFO | utils.basic_utils : Train Epoch: [0]  [   10/10397]  eta: 22 days, 12:37:07  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 2.5755  time: 187.3715  data: 184.3702  max mem: 42891 res mem: 47418
2024-02-26T17:16:36 | INFO | utils.basic_utils : Train Epoch: [0]  [   20/10397]  eta: 16 days, 19:23:10  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 1.9239  time: 87.6333  data: 84.2454  max mem: 42891 res mem: 47418
2024-02-26T17:32:33 | INFO | utils.basic_utils : Train Epoch: [0]  [   30/10397]  eta: 15 days, 1:57:15  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 1.8293  time: 91.7663  data: 81.1152  max mem: 42891 res mem: 47418
2024-02-26T17:59:08 | INFO | utils.basic_utils : Train Epoch: [0]  [   40/10397]  eta: 16 days, 1:18:23  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 1.8801  time: 127.6142  data: 114.4538  max mem: 42891 res mem: 47418
2024-02-26T18:12:28 | INFO | utils.basic_utils : Train Epoch: [0]  [   50/10397]  eta: 14 days, 18:34:29  lr: 0.000002  temperature: 0.0101  video-loss_vtc: 1.7037  time: 119.7631  data: 108.4889  max mem: 42891 res mem: 47418
2024-02-26T18:25:45 | INFO | utils.basic_utils : Train Epoch: [0]  [   60/10397]  eta: 13 days, 21:39:25  lr: 0.000002  temperature: 0.0101  video-loss_vtc: 1.7889  time: 79.8571  data: 66.4100  max mem: 42891 res mem: 47418
2024-02-26T18:41:19 | INFO | utils.basic_utils : Train Epoch: [0]  [   70/10397]  eta: 13 days, 12:06:27  lr: 0.000003  temperature: 0.0101  video-loss_vtc: 1.5774  time: 86.5099  data: 71.7487  max mem: 42891 res mem: 47418
2024-02-26T19:05:53 | INFO | utils.basic_utils : Train Epoch: [0]  [   80/10397]  eta: 13 days, 23:58:33  lr: 0.000003  temperature: 0.0101  video-loss_vtc: 1.7242  time: 120.3902  data: 107.8296  max mem: 42891 res mem: 47418
2024-02-26T19:19:07 | INFO | utils.basic_utils : Train Epoch: [0]  [   90/10397]  eta: 13 days, 11:44:40  lr: 0.000004  temperature: 0.0101  video-loss_vtc: 1.5329  time: 113.4049  data: 104.2242  max mem: 42891 res mem: 47418
2024-02-26T19:32:45 | INFO | utils.basic_utils : Train Epoch: [0]  [  100/10397]  eta: 13 days, 2:34:27  lr: 0.000004  temperature: 0.0101  video-loss_vtc: 1.6223  time: 80.5988  data: 69.5416  max mem: 42891 res mem: 47418
2024-02-26T19:48:31 | INFO | utils.basic_utils : Train Epoch: [0]  [  110/10397]  eta: 12 days, 22:18:23  lr: 0.000004  temperature: 0.0101  video-loss_vtc: 1.5056  time: 88.1967  data: 70.8723  max mem: 42891 res mem: 47418
2024-02-26T20:13:03 | INFO | utils.basic_utils : Train Epoch: [0]  [  120/10397]  eta: 13 days, 7:06:37  lr: 0.000005  temperature: 0.0102  video-loss_vtc: 1.4340  time: 120.8888  data: 104.7031  max mem: 42891 res mem: 47418
2024-02-26T20:26:50 | INFO | utils.basic_utils : Train Epoch: [0]  [  130/10397]  eta: 13 days, 0:28:13  lr: 0.000005  temperature: 0.0102  video-loss_vtc: 1.5689  time: 114.9489  data: 103.1749  max mem: 42891 res mem: 47418
2024-02-26T20:40:12 | INFO | utils.basic_utils : Train Epoch: [0]  [  140/10397]  eta: 12 days, 18:14:38  lr: 0.000005  temperature: 0.0102  video-loss_vtc: 1.4362  time: 81.4829  data: 71.0230  max mem: 42891 res mem: 47418
2024-02-26T20:54:15 | INFO | utils.basic_utils : Train Epoch: [0]  [  150/10397]  eta: 12 days, 13:34:45  lr: 0.000006  temperature: 0.0102  video-loss_vtc: 1.9700  time: 82.2904  data: 75.4799  max mem: 42891 res mem: 47418
2024-02-26T21:20:35 | INFO | utils.basic_utils : Train Epoch: [0]  [  160/10397]  eta: 12 days, 22:28:14  lr: 0.000006  temperature: 0.0102  video-loss_vtc: 1.4542  time: 121.1413  data: 113.9286  max mem: 42891 res mem: 47418
2024-02-26T21:34:41 | INFO | utils.basic_utils : Train Epoch: [0]  [  170/10397]  eta: 12 days, 18:05:23  lr: 0.000007  temperature: 0.0102  video-loss_vtc: 1.5326  time: 121.2984  data: 112.6345  max mem: 42891 res mem: 47418
2024-02-26T21:49:57 | INFO | utils.basic_utils : Train Epoch: [0]  [  180/10397]  eta: 12 days, 15:14:48  lr: 0.000007  temperature: 0.0102  video-loss_vtc: 1.6616  time: 88.0808  data: 72.0837  max mem: 42891 res mem: 47418
2024-02-26T22:03:38 | INFO | utils.basic_utils : Train Epoch: [0]  [  190/10397]  eta: 12 days, 11:16:33  lr: 0.000007  temperature: 0.0102  video-loss_vtc: 1.7847  time: 86.8110  data: 67.3713  max mem: 42891 res mem: 47418
2024-02-26T22:29:26 | INFO | utils.basic_utils : Train Epoch: [0]  [  200/10397]  eta: 12 days, 17:55:34  lr: 0.000008  temperature: 0.0103  video-loss_vtc: 1.3473  time: 118.4630  data: 99.7908  max mem: 42891 res mem: 47418
2024-02-26T22:43:49 | INFO | utils.basic_utils : Train Epoch: [0]  [  210/10397]  eta: 12 days, 14:43:13  lr: 0.000008  temperature: 0.0103  video-loss_vtc: 1.4630  time: 120.5828  data: 95.9754  max mem: 42891 res mem: 47418
2024-02-26T22:58:26 | INFO | utils.basic_utils : Train Epoch: [0]  [  220/10397]  eta: 12 days, 11:57:11  lr: 0.000009  temperature: 0.0103  video-loss_vtc: 1.4807  time: 87.0034  data: 58.7118  max mem: 42891 res mem: 47418
2024-02-26T23:11:40 | INFO | utils.basic_utils : Train Epoch: [0]  [  230/10397]  eta: 12 days, 8:23:48  lr: 0.000009  temperature: 0.0103  video-loss_vtc: 1.3865  time: 83.5480  data: 56.1787  max mem: 42891 res mem: 47418
2024-02-26T23:38:41 | INFO | utils.basic_utils : Train Epoch: [0]  [  240/10397]  eta: 12 days, 14:47:13  lr: 0.000009  temperature: 0.0103  video-loss_vtc: 1.8295  time: 120.7270  data: 73.5933  max mem: 42891 res mem: 47418
2024-02-26T23:52:58 | INFO | utils.basic_utils : Train Epoch: [0]  [  250/10397]  eta: 12 days, 12:04:17  lr: 0.000010  temperature: 0.0103  video-loss_vtc: 1.2601  time: 123.9079  data: 73.5761  max mem: 42891 res mem: 47418
2024-02-27T00:06:44 | INFO | utils.basic_utils : Train Epoch: [0]  [  260/10397]  eta: 12 days, 9:12:01  lr: 0.000010  temperature: 0.0103  video-loss_vtc: 1.4186  time: 84.1902  data: 47.6702  max mem: 42891 res mem: 47418
2024-02-27T00:20:40 | INFO | utils.basic_utils : Train Epoch: [0]  [  270/10397]  eta: 12 days, 6:37:36  lr: 0.000010  temperature: 0.0103  video-loss_vtc: 1.2697  time: 83.0840  data: 39.8459  max mem: 42891 res mem: 47418
2024-02-27T00:47:07 | INFO | utils.basic_utils : Train Epoch: [0]  [  280/10397]  eta: 12 days, 11:43:56  lr: 0.000011  temperature: 0.0103  video-loss_vtc: 1.3498  time: 121.1356  data: 62.0166  max mem: 42891 res mem: 47418
2024-02-27T01:00:49 | INFO | utils.basic_utils : Train Epoch: [0]  [  290/10397]  eta: 12 days, 9:04:40  lr: 0.000011  temperature: 0.0103  video-loss_vtc: 1.1416  time: 120.4543  data: 68.5209  max mem: 42891 res mem: 47418
2024-02-27T01:13:59 | INFO | utils.basic_utils : Train Epoch: [0]  [  300/10397]  eta: 12 days, 6:17:13  lr: 0.000012  temperature: 0.0104  video-loss_vtc: 1.2685  time: 80.6165  data: 45.0869  max mem: 42891 res mem: 47418
2024-02-27T01:28:20 | INFO | utils.basic_utils : Train Epoch: [0]  [  310/10397]  eta: 12 days, 4:17:39  lr: 0.000012  temperature: 0.0104  video-loss_vtc: 1.2618  time: 82.5306  data: 38.1381  max mem: 42891 res mem: 47418
2024-02-27T01:55:10 | INFO | utils.basic_utils : Train Epoch: [0]  [  320/10397]  eta: 12 days, 8:57:02  lr: 0.000012  temperature: 0.0104  video-loss_vtc: 1.6287  time: 123.5408  data: 56.9136  max mem: 42891 res mem: 47418
2024-02-27T02:09:41 | INFO | utils.basic_utils : Train Epoch: [0]  [  330/10397]  eta: 12 days, 7:02:46  lr: 0.000013  temperature: 0.0105  video-loss_vtc: 1.3176  time: 124.0347  data: 56.7001  max mem: 42891 res mem: 47418
2024-02-27T02:23:55 | INFO | utils.basic_utils : Train Epoch: [0]  [  340/10397]  eta: 12 days, 5:06:37  lr: 0.000013  temperature: 0.0105  video-loss_vtc: 1.3859  time: 86.2437  data: 35.3244  max mem: 42891 res mem: 47418
2024-02-27T02:37:27 | INFO | utils.basic_utils : Train Epoch: [0]  [  350/10397]  eta: 12 days, 2:55:50  lr: 0.000014  temperature: 0.0105  video-loss_vtc: 1.1898  time: 83.3153  data: 36.4934  max mem: 42891 res mem: 47418
2024-02-27T03:05:52 | INFO | utils.basic_utils : Train Epoch: [0]  [  360/10397]  eta: 12 days, 7:45:32  lr: 0.000014  temperature: 0.0105  video-loss_vtc: 1.6266  time: 125.8424  data: 60.4899  max mem: 42891 res mem: 47418
2024-02-27T03:19:59 | INFO | utils.basic_utils : Train Epoch: [0]  [  370/10397]  eta: 12 days, 5:51:21  lr: 0.000014  temperature: 0.0105  video-loss_vtc: 1.3139  time: 127.5846  data: 61.7285  max mem: 42891 res mem: 47418
2024-02-27T03:34:30 | INFO | utils.basic_utils : Train Epoch: [0]  [  380/10397]  eta: 12 days, 4:13:28  lr: 0.000015  temperature: 0.0105  video-loss_vtc: 1.3810  time: 85.9176  data: 42.2273  max mem: 42891 res mem: 47418
2024-02-27T03:48:17 | INFO | utils.basic_utils : Train Epoch: [0]  [  390/10397]  eta: 12 days, 2:20:25  lr: 0.000015  temperature: 0.0105  video-loss_vtc: 1.2227  time: 84.9010  data: 42.3062  max mem: 42891 res mem: 47418
2024-02-27T04:15:58 | INFO | utils.basic_utils : Train Epoch: [0]  [  400/10397]  eta: 12 days, 6:19:13  lr: 0.000015  temperature: 0.0105  video-loss_vtc: 1.2399  time: 124.3683  data: 67.2299  max mem: 42891 res mem: 47418
2024-02-27T04:29:54 | INFO | utils.basic_utils : Train Epoch: [0]  [  410/10397]  eta: 12 days, 4:30:50  lr: 0.000016  temperature: 0.0105  video-loss_vtc: 1.2016  time: 124.8491  data: 67.8630  max mem: 42891 res mem: 47418
2024-02-27T04:43:58 | INFO | utils.basic_utils : Train Epoch: [0]  [  420/10397]  eta: 12 days, 2:50:10  lr: 0.000016  temperature: 0.0105  video-loss_vtc: 1.2262  time: 83.9956  data: 44.8149  max mem: 42891 res mem: 47418
2024-02-27T04:58:08 | INFO | utils.basic_utils : Train Epoch: [0]  [  430/10397]  eta: 12 days, 1:15:50  lr: 0.000017  temperature: 0.0105  video-loss_vtc: 1.1887  time: 84.7039  data: 47.8650  max mem: 42891 res mem: 47418
2024-02-27T05:25:54 | INFO | utils.basic_utils : Train Epoch: [0]  [  440/10397]  eta: 12 days, 4:52:16  lr: 0.000017  temperature: 0.0105  video-loss_vtc: 1.2403  time: 125.8133  data: 76.9290  max mem: 42891 res mem: 47418
2024-02-27T05:40:05 | INFO | utils.basic_utils : Train Epoch: [0]  [  450/10397]  eta: 12 days, 3:18:08  lr: 0.000017  temperature: 0.0106  video-loss_vtc: 1.2273  time: 125.8528  data: 76.5385  max mem: 42891 res mem: 47418
2024-02-27T05:54:42 | INFO | utils.basic_utils : Train Epoch: [0]  [  460/10397]  eta: 12 days, 1:56:49  lr: 0.000018  temperature: 0.0106  video-loss_vtc: 1.3010  time: 86.3831  data: 49.2487  max mem: 42891 res mem: 47418
2024-02-27T06:08:41 | INFO | utils.basic_utils : Train Epoch: [0]  [  470/10397]  eta: 12 days, 0:25:22  lr: 0.000018  temperature: 0.0106  video-loss_vtc: 1.2816  time: 85.8388  data: 48.5747  max mem: 42891 res mem: 47418
2024-02-27T06:35:54 | INFO | utils.basic_utils : Train Epoch: [0]  [  480/10397]  eta: 12 days, 3:29:21  lr: 0.000019  temperature: 0.0106  video-loss_vtc: 1.2327  time: 123.6023  data: 71.6469  max mem: 42891 res mem: 47418
2024-02-27T06:49:42 | INFO | utils.basic_utils : Train Epoch: [0]  [  490/10397]  eta: 12 days, 1:54:18  lr: 0.000019  temperature: 0.0106  video-loss_vtc: 1.2197  time: 123.0016  data: 70.2170  max mem: 42891 res mem: 47418
2024-02-27T07:03:42 | INFO | utils.basic_utils : Train Epoch: [0]  [  500/10397]  eta: 12 days, 0:26:42  lr: 0.000019  temperature: 0.0106  video-loss_vtc: 1.1911  time: 83.4332  data: 44.7786  max mem: 42891 res mem: 47418
2024-02-27T07:17:30 | INFO | utils.basic_utils : Train Epoch: [0]  [  510/10397]  eta: 11 days, 22:57:51  lr: 0.000020  temperature: 0.0106  video-loss_vtc: 1.2286  time: 83.4328  data: 46.4600  max mem: 42891 res mem: 47418
2024-02-27T07:44:00 | INFO | utils.basic_utils : Train Epoch: [0]  [  520/10397]  eta: 12 days, 1:32:40  lr: 0.000020  temperature: 0.0107  video-loss_vtc: 1.2007  time: 120.8939  data: 70.5834  max mem: 42891 res mem: 47418
2024-02-27T07:56:45 | INFO | utils.basic_utils : Train Epoch: [0]  [  530/10397]  eta: 11 days, 23:45:05  lr: 0.000020  temperature: 0.0106  video-loss_vtc: 1.1438  time: 117.7358  data: 68.2720  max mem: 42891 res mem: 47418
2024-02-27T08:10:19 | INFO | utils.basic_utils : Train Epoch: [0]  [  540/10397]  eta: 11 days, 22:15:58  lr: 0.000021  temperature: 0.0106  video-loss_vtc: 1.4709  time: 78.9376  data: 46.2379  max mem: 42892 res mem: 47418
2024-02-27T08:23:57 | INFO | utils.basic_utils : Train Epoch: [0]  [  550/10397]  eta: 11 days, 20:50:39  lr: 0.000021  temperature: 0.0107  video-loss_vtc: 1.4193  time: 81.5797  data: 50.2340  max mem: 42892 res mem: 47418
2024-02-27T08:50:13 | INFO | utils.basic_utils : Train Epoch: [0]  [  560/10397]  eta: 11 days, 23:09:41  lr: 0.000022  temperature: 0.0107  video-loss_vtc: 1.2732  time: 119.7040  data: 69.6950  max mem: 42892 res mem: 47418
2024-02-27T09:03:04 | INFO | utils.basic_utils : Train Epoch: [0]  [  570/10397]  eta: 11 days, 21:31:57  lr: 0.000022  temperature: 0.0107  video-loss_vtc: 1.3339  time: 117.3877  data: 64.1515  max mem: 42892 res mem: 47418
2024-02-27T09:16:25 | INFO | utils.basic_utils : Train Epoch: [0]  [  580/10397]  eta: 11 days, 20:05:25  lr: 0.000022  temperature: 0.0107  video-loss_vtc: 1.2323  time: 78.5949  data: 39.0711  max mem: 42892 res mem: 47418
2024-02-27T09:29:23 | INFO | utils.basic_utils : Train Epoch: [0]  [  590/10397]  eta: 11 days, 18:35:09  lr: 0.000023  temperature: 0.0106  video-loss_vtc: 1.4204  time: 78.9406  data: 35.4854  max mem: 42892 res mem: 47418
2024-02-27T09:55:24 | INFO | utils.basic_utils : Train Epoch: [0]  [  600/10397]  eta: 11 days, 20:40:14  lr: 0.000023  temperature: 0.0106  video-loss_vtc: 1.4130  time: 116.9783  data: 41.8846  max mem: 42892 res mem: 47418
2024-02-27T10:09:31 | INFO | utils.basic_utils : Train Epoch: [0]  [  610/10397]  eta: 11 days, 19:29:35  lr: 0.000024  temperature: 0.0107  video-loss_vtc: 1.1276  time: 120.4036  data: 36.2452  max mem: 42892 res mem: 47418
2024-02-27T10:23:39 | INFO | utils.basic_utils : Train Epoch: [0]  [  620/10397]  eta: 11 days, 18:21:09  lr: 0.000024  temperature: 0.0107  video-loss_vtc: 1.0805  time: 84.7451  data: 21.6500  max mem: 42892 res mem: 47418
2024-02-27T10:38:15 | INFO | utils.basic_utils : Train Epoch: [0]  [  630/10397]  eta: 11 days, 17:21:26  lr: 0.000024  temperature: 0.0107  video-loss_vtc: 1.2091  time: 86.1777  data: 24.1042  max mem: 42892 res mem: 47418
2024-02-27T11:02:47 | INFO | utils.basic_utils : Train Epoch: [0]  [  640/10397]  eta: 11 days, 18:54:31  lr: 0.000025  temperature: 0.0107  video-loss_vtc: 1.1984  time: 117.3735  data: 37.0039  max mem: 42892 res mem: 47418
2024-02-27T11:19:39 | INFO | utils.basic_utils : Train Epoch: [0]  [  650/10397]  eta: 11 days, 18:29:17  lr: 0.000025  temperature: 0.0107  video-loss_vtc: 1.1853  time: 124.2270  data: 32.7986  max mem: 42892 res mem: 47418
2024-02-27T11:33:21 | INFO | utils.basic_utils : Train Epoch: [0]  [  660/10397]  eta: 11 days, 17:17:28  lr: 0.000025  temperature: 0.0107  video-loss_vtc: 1.2568  time: 91.7029  data: 16.3076  max mem: 42892 res mem: 47418
2024-02-27T11:47:19 | INFO | utils.basic_utils : Train Epoch: [0]  [  670/10397]  eta: 11 days, 16:11:15  lr: 0.000026  temperature: 0.0107  video-loss_vtc: 1.4407  time: 82.9682  data: 14.8039  max mem: 42892 res mem: 47418
2024-02-27T12:11:10 | INFO | utils.basic_utils : Train Epoch: [0]  [  680/10397]  eta: 11 days, 17:27:39  lr: 0.000026  temperature: 0.0107  video-loss_vtc: 1.2430  time: 113.4293  data: 15.1991  max mem: 42892 res mem: 47418
2024-02-27T12:29:02 | INFO | utils.basic_utils : Train Epoch: [0]  [  690/10397]  eta: 11 days, 17:17:07  lr: 0.000027  temperature: 0.0107  video-loss_vtc: 1.4431  time: 125.1471  data: 9.4453  max mem: 42892 res mem: 47418
2024-02-27T12:42:17 | INFO | utils.basic_utils : Train Epoch: [0]  [  700/10397]  eta: 11 days, 16:02:42  lr: 0.000027  temperature: 0.0107  video-loss_vtc: 1.2895  time: 93.3934  data: 4.1076  max mem: 42892 res mem: 47418
2024-02-27T12:54:59 | INFO | utils.basic_utils : Train Epoch: [0]  [  710/10397]  eta: 11 days, 14:42:17  lr: 0.000027  temperature: 0.0107  video-loss_vtc: 1.3851  time: 77.8800  data: 1.8215  max mem: 42892 res mem: 47418
2024-02-27T13:19:55 | INFO | utils.basic_utils : Train Epoch: [0]  [  720/10397]  eta: 11 days, 16:07:56  lr: 0.000028  temperature: 0.0107  video-loss_vtc: 1.4678  time: 112.8805  data: 0.0004  max mem: 42892 res mem: 47418
2024-02-27T13:35:00 | INFO | utils.basic_utils : Train Epoch: [0]  [  730/10397]  eta: 11 days, 15:20:20  lr: 0.000028  temperature: 0.0107  video-loss_vtc: 1.1315  time: 120.0410  data: 0.7431  max mem: 42892 res mem: 47418
2024-02-27T13:47:56 | INFO | utils.basic_utils : Train Epoch: [0]  [  740/10397]  eta: 11 days, 14:05:35  lr: 0.000029  temperature: 0.0107  video-loss_vtc: 1.2422  time: 84.0464  data: 2.5009  max mem: 42892 res mem: 47418
2024-02-27T14:02:13 | INFO | utils.basic_utils : Train Epoch: [0]  [  750/10397]  eta: 11 days, 13:09:52  lr: 0.000029  temperature: 0.0107  video-loss_vtc: 1.2566  time: 81.6543  data: 2.7533  max mem: 42892 res mem: 47418
2024-02-27T14:27:49 | INFO | utils.basic_utils : Train Epoch: [0]  [  760/10397]  eta: 11 days, 14:38:23  lr: 0.000029  temperature: 0.0107  video-loss_vtc: 1.5603  time: 119.6290  data: 4.9536  max mem: 42892 res mem: 47418
2024-02-27T14:41:57 | INFO | utils.basic_utils : Train Epoch: [0]  [  770/10397]  eta: 11 days, 13:40:58  lr: 0.000030  temperature: 0.0107  video-loss_vtc: 1.2135  time: 119.1865  data: 8.3050  max mem: 42892 res mem: 47418
2024-02-27T14:54:42 | INFO | utils.basic_utils : Train Epoch: [0]  [  780/10397]  eta: 11 days, 12:27:34  lr: 0.000030  temperature: 0.0107  video-loss_vtc: 1.1858  time: 80.6691  data: 10.1016  max mem: 42892 res mem: 47418
2024-02-27T15:07:47 | INFO | utils.basic_utils : Train Epoch: [0]  [  790/10397]  eta: 11 days, 11:19:50  lr: 0.000030  temperature: 0.0108  video-loss_vtc: 1.9347  time: 77.5263  data: 10.0535  max mem: 42892 res mem: 47418
2024-02-27T15:34:04 | INFO | utils.basic_utils : Train Epoch: [0]  [  800/10397]  eta: 11 days, 12:51:27  lr: 0.000031  temperature: 0.0109  video-loss_vtc: 1.1288  time: 118.1058  data: 14.6321  max mem: 42892 res mem: 47418
2024-02-27T15:48:23 | INFO | utils.basic_utils : Train Epoch: [0]  [  810/10397]  eta: 11 days, 11:58:44  lr: 0.000031  temperature: 0.0108  video-loss_vtc: 1.1302  time: 121.7743  data: 16.7418  max mem: 42892 res mem: 47418
2024-02-27T16:01:08 | INFO | utils.basic_utils : Train Epoch: [0]  [  820/10397]  eta: 11 days, 10:48:47  lr: 0.000032  temperature: 0.0108  video-loss_vtc: 1.1516  time: 81.2122  data: 12.8402  max mem: 42892 res mem: 47418
2024-02-27T16:14:53 | INFO | utils.basic_utils : Train Epoch: [0]  [  830/10397]  eta: 11 days, 9:51:33  lr: 0.000032  temperature: 0.0109  video-loss_vtc: 1.1923  time: 79.4924  data: 15.1461  max mem: 42892 res mem: 47418
2024-02-27T16:41:35 | INFO | utils.basic_utils : Train Epoch: [0]  [  840/10397]  eta: 11 days, 11:22:40  lr: 0.000032  temperature: 0.0108  video-loss_vtc: 1.1558  time: 121.3346  data: 18.0894  max mem: 42892 res mem: 47418
2024-02-27T16:54:34 | INFO | utils.basic_utils : Train Epoch: [0]  [  850/10397]  eta: 11 days, 10:17:04  lr: 0.000033  temperature: 0.0108  video-loss_vtc: 1.3519  time: 119.0599  data: 14.7172  max mem: 42892 res mem: 47418
2024-02-27T17:08:10 | INFO | utils.basic_utils : Train Epoch: [0]  [  860/10397]  eta: 11 days, 9:19:30  lr: 0.000033  temperature: 0.0109  video-loss_vtc: 1.3316  time: 79.7388  data: 11.8613  max mem: 42892 res mem: 47418
2024-02-27T17:21:52 | INFO | utils.basic_utils : Train Epoch: [0]  [  870/10397]  eta: 11 days, 8:24:10  lr: 0.000034  temperature: 0.0108  video-loss_vtc: 1.2701  time: 81.9181  data: 10.5322  max mem: 42892 res mem: 47418
2024-02-27T17:49:19 | INFO | utils.basic_utils : Train Epoch: [0]  [  880/10397]  eta: 11 days, 9:58:13  lr: 0.000034  temperature: 0.0108  video-loss_vtc: 1.2726  time: 123.4780  data: 12.2535  max mem: 42892 res mem: 47418
2024-02-27T18:03:27 | INFO | utils.basic_utils : Train Epoch: [0]  [  890/10397]  eta: 11 days, 9:07:26  lr: 0.000034  temperature: 0.0108  video-loss_vtc: 1.2895  time: 124.7478  data: 11.3573  max mem: 42892 res mem: 47418
2024-02-27T18:16:14 | INFO | utils.basic_utils : Train Epoch: [0]  [  900/10397]  eta: 11 days, 8:03:16  lr: 0.000035  temperature: 0.0109  video-loss_vtc: 1.1905  time: 80.7522  data: 3.4630  max mem: 42892 res mem: 47418
2024-02-27T18:29:37 | INFO | utils.basic_utils : Train Epoch: [0]  [  910/10397]  eta: 11 days, 7:06:21  lr: 0.000035  temperature: 0.0108  video-loss_vtc: 1.1849  time: 78.4733  data: 5.5390  max mem: 42892 res mem: 47418
2024-02-27T18:55:00 | INFO | utils.basic_utils : Train Epoch: [0]  [  920/10397]  eta: 11 days, 8:13:56  lr: 0.000035  temperature: 0.0110  video-loss_vtc: 1.5573  time: 116.2577  data: 10.7603  max mem: 42892 res mem: 47418
2024-02-27T19:10:08 | INFO | utils.basic_utils : Train Epoch: [0]  [  930/10397]  eta: 11 days, 7:35:22  lr: 0.000036  temperature: 0.0110  video-loss_vtc: 1.1749  time: 121.5517  data: 15.3491  max mem: 42892 res mem: 47418
2024-02-27T19:23:45 | INFO | utils.basic_utils : Train Epoch: [0]  [  940/10397]  eta: 11 days, 6:42:03  lr: 0.000036  temperature: 0.0109  video-loss_vtc: 1.2094  time: 86.2711  data: 15.0830  max mem: 42892 res mem: 47418
2024-02-27T19:37:46 | INFO | utils.basic_utils : Train Epoch: [0]  [  950/10397]  eta: 11 days, 5:53:35  lr: 0.000037  temperature: 0.0108  video-loss_vtc: 1.1635  time: 82.9345  data: 12.0623  max mem: 42892 res mem: 47418
2024-02-27T20:00:03 | INFO | vindlu : Logging to: exp/exp_pretrain_videoclip/viclip_base/viclip_base/train.log
2024-02-27T20:00:03 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: VindLU_VideoCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_videoclip/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-27T20:00:03 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-27T20:00:03 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-27T20:00:03 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-27T20:00:03 | INFO | __main__ : Creating dataset for pt
2024-02-27T20:00:03 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-27T20:01:04 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-27T20:01:04 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-27T20:01:33 | INFO | tasks.shared_utils : Creating model
2024-02-27T20:01:33 | INFO | models.vindlu_videoclip : vision encoder name: vit_b16
2024-02-27T20:01:34 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-27T20:01:34 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-27T20:01:34 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-27T20:01:34 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-27T20:01:34 | INFO | models.vindlu_videoclip : text encoder name: vit_b16
2024-02-27T20:01:35 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-27T20:01:37 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-27T20:01:37 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-27T20:01:37 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-27T20:01:37 | INFO | tasks.shared_utils : Auto resuming
2024-02-27T20:01:37 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_videoclip/viclip_base/viclip_base
2024-02-27T20:01:37 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-27T20:01:37 | INFO | __main__ : Start training
2024-02-27T20:01:38 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-27T20:04:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T20:04:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-27T21:02:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-27T21:02:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-27T21:04:26 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2599]  eta: 113 days, 8:09:28  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 6.2077  time: 3767.8218  data: 3633.2720  max mem: 41900 res mem: 46642
2024-02-27T21:04:26 | INFO | torch.nn.parallel.distributed : Reducer buckets have been rebuilt in this iteration.
2024-02-27T22:03:43 | INFO | utils.basic_utils : Train Epoch: [0]  [  10/2599]  eta: 19 days, 22:54:45  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 4.0877  time: 665.9272  data: 606.8767  max mem: 42890 res mem: 47418
2024-02-27T23:02:50 | INFO | utils.basic_utils : Train Epoch: [0]  [  20/2599]  eta: 15 days, 10:52:06  lr: 0.000003  temperature: 0.0100  video-loss_vtc: 3.3688  time: 355.1850  data: 302.7979  max mem: 42891 res mem: 47418
2024-02-28T00:01:31 | INFO | utils.basic_utils : Train Epoch: [0]  [  30/2599]  eta: 13 days, 19:19:10  lr: 0.000005  temperature: 0.0101  video-loss_vtc: 3.1628  time: 353.3830  data: 282.7469  max mem: 42891 res mem: 47418
2024-02-28T01:52:45 | INFO | utils.basic_utils : Train Epoch: [0]  [  40/2599]  eta: 15 days, 5:14:32  lr: 0.000006  temperature: 0.0101  video-loss_vtc: 2.9079  time: 509.7610  data: 406.9885  max mem: 42891 res mem: 47418
2024-02-28T02:55:51 | INFO | utils.basic_utils : Train Epoch: [0]  [  50/2599]  eta: 14 days, 9:02:13  lr: 0.000008  temperature: 0.0101  video-loss_vtc: 2.5090  time: 522.9775  data: 400.7408  max mem: 42891 res mem: 47418
2024-02-28T03:55:19 | INFO | utils.basic_utils : Train Epoch: [0]  [  60/2599]  eta: 13 days, 16:35:53  lr: 0.000009  temperature: 0.0102  video-loss_vtc: 2.6291  time: 367.6980  data: 243.5956  max mem: 42891 res mem: 47418
2024-02-28T04:54:23 | INFO | utils.basic_utils : Train Epoch: [0]  [  70/2599]  eta: 13 days, 4:16:07  lr: 0.000011  temperature: 0.0102  video-loss_vtc: 2.8503  time: 355.6056  data: 237.1452  max mem: 42891 res mem: 47418
2024-02-28T06:39:26 | INFO | utils.basic_utils : Train Epoch: [0]  [  80/2599]  eta: 13 days, 18:34:27  lr: 0.000012  temperature: 0.0102  video-loss_vtc: 2.4510  time: 492.3329  data: 348.6151  max mem: 42891 res mem: 47418
2024-02-28T07:44:37 | INFO | utils.basic_utils : Train Epoch: [0]  [  90/2599]  eta: 13 days, 11:01:56  lr: 0.000014  temperature: 0.0103  video-loss_vtc: 2.3793  time: 510.6902  data: 335.7354  max mem: 42891 res mem: 47418
2024-02-28T08:41:57 | INFO | utils.basic_utils : Train Epoch: [0]  [ 100/2599]  eta: 13 days, 1:32:13  lr: 0.000016  temperature: 0.0103  video-loss_vtc: 2.1394  time: 367.5853  data: 214.1773  max mem: 42891 res mem: 47418
2024-02-28T09:48:27 | INFO | utils.basic_utils : Train Epoch: [0]  [ 110/2599]  eta: 12 days, 21:00:09  lr: 0.000017  temperature: 0.0103  video-loss_vtc: 2.1534  time: 371.5466  data: 200.5714  max mem: 42891 res mem: 47418
2024-02-28T10:52:01 | INFO | vindlu : Logging to: exp/exp_pretrain_videoclip/viclip_base/viclip_base/train.log
2024-02-28T10:52:01 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: VindLU_VideoCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_videoclip/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-28T10:52:01 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-28T10:52:01 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-28T10:52:01 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-28T10:52:01 | INFO | __main__ : Creating dataset for pt
2024-02-28T10:52:01 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-28T10:52:58 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-28T10:52:59 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-28T10:53:23 | INFO | tasks.shared_utils : Creating model
2024-02-28T10:53:23 | INFO | models.vindlu_videoclip : vision encoder name: vit_b16
2024-02-28T10:53:24 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-28T10:53:25 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-28T10:53:25 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-28T10:53:25 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-28T10:53:25 | INFO | models.vindlu_videoclip : text encoder name: vit_b16
2024-02-28T10:53:25 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-28T10:53:26 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-28T10:53:26 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-28T10:53:26 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-28T10:53:26 | INFO | tasks.shared_utils : Auto resuming
2024-02-28T10:53:26 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_videoclip/viclip_base/viclip_base
2024-02-28T10:53:26 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-28T10:53:26 | INFO | __main__ : Start training
2024-02-28T10:53:28 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-28T10:55:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:34 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:34 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:36 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:36 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:41 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:41 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T10:55:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T11:47:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-28T11:47:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-28T11:49:52 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2599]  eta: 101 days, 19:30:18  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 6.2085  time: 3384.6165  data: 3252.5850  max mem: 41900 res mem: 46642
2024-02-28T11:49:55 | INFO | torch.nn.parallel.distributed : Reducer buckets have been rebuilt in this iteration.
2024-02-28T12:43:12 | INFO | utils.basic_utils : Train Epoch: [0]  [  10/2599]  eta: 17 days, 22:30:37  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 4.0824  time: 598.6241  data: 540.5585  max mem: 42890 res mem: 47418
2024-02-28T13:37:05 | INFO | utils.basic_utils : Train Epoch: [0]  [  20/2599]  eta: 13 days, 22:54:35  lr: 0.000003  temperature: 0.0100  video-loss_vtc: 3.3668  time: 321.6415  data: 272.0270  max mem: 42890 res mem: 47418
2024-02-28T14:30:23 | INFO | utils.basic_utils : Train Epoch: [0]  [  30/2599]  eta: 12 days, 11:36:16  lr: 0.000005  temperature: 0.0101  video-loss_vtc: 3.1623  time: 321.5133  data: 261.3676  max mem: 42890 res mem: 47418
2024-02-28T18:48:52 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-28T18:48:52 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: VindLU_VideoCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-28T18:48:52 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-28T18:48:53 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-28T18:48:53 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-28T18:48:53 | INFO | __main__ : Creating dataset for pt
2024-02-28T18:48:53 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-28T18:50:01 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-28T18:50:01 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-28T18:55:02 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-28T18:55:02 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-28T18:55:02 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-28T18:55:02 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-28T18:55:02 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-28T18:55:02 | INFO | __main__ : Creating dataset for pt
2024-02-28T18:55:02 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-28T18:55:57 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-28T18:55:57 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-28T18:56:23 | INFO | tasks.shared_utils : Creating model
2024-02-28T18:56:23 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-28T18:56:24 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-28T18:56:24 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-28T18:56:24 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-28T18:56:25 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-28T18:56:25 | INFO | models.viclip : text encoder name: vit_b16
2024-02-28T18:56:25 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-28T18:56:26 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-28T18:56:26 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-28T18:56:26 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-28T18:56:26 | INFO | tasks.shared_utils : Auto resuming
2024-02-28T18:56:26 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-28T18:56:26 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-28T18:56:26 | INFO | __main__ : Start training
2024-02-28T18:56:28 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-28T18:58:56 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:58:56 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:04 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:04 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:16 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-28T18:59:16 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:01:49 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T13:01:49 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T13:01:49 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T13:01:49 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T13:01:49 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T13:01:49 | INFO | __main__ : Creating dataset for pt
2024-02-29T13:01:49 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T13:02:47 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T13:02:47 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T13:03:10 | INFO | tasks.shared_utils : Creating model
2024-02-29T13:03:10 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T13:03:10 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T13:03:11 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T13:03:11 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T13:03:11 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T13:03:11 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T13:03:11 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T13:03:12 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T13:03:12 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T13:03:12 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T13:03:12 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T13:03:12 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T13:03:12 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T13:03:12 | INFO | __main__ : Start training
2024-02-29T13:03:14 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T13:05:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T13:05:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:01:07 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T14:01:07 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T14:01:07 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T14:01:07 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T14:01:07 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T14:01:07 | INFO | __main__ : Creating dataset for pt
2024-02-29T14:01:07 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T14:02:01 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T14:02:01 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T14:02:25 | INFO | tasks.shared_utils : Creating model
2024-02-29T14:02:25 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T14:02:26 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T14:02:26 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T14:02:26 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T14:02:26 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T14:02:26 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T14:02:27 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T14:02:28 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T14:02:28 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T14:02:28 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T14:02:28 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T14:02:28 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T14:02:28 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T14:02:28 | INFO | __main__ : Start training
2024-02-29T14:02:29 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T14:04:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:39 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:39 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:04:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T14:57:00 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-29T14:57:00 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-02-29T14:59:09 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2599]  eta: 102 days, 6:39:54  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 6.2085  time: 3400.0747  data: 3263.3269  max mem: 41898 res mem: 46648
2024-02-29T15:53:56 | INFO | utils.basic_utils : Train Epoch: [0]  [  10/2599]  eta: 18 days, 5:12:37  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 4.0844  time: 607.9406  data: 544.2435  max mem: 42889 res mem: 47424
2024-02-29T16:02:59 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T16:02:59 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T16:02:59 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T16:02:59 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T16:02:59 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T16:02:59 | INFO | __main__ : Creating dataset for pt
2024-02-29T16:02:59 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T16:03:58 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T16:03:58 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T16:04:20 | INFO | tasks.shared_utils : Creating model
2024-02-29T16:04:20 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T16:04:21 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T16:04:21 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T16:04:21 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T16:04:21 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T16:04:21 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T16:04:22 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T16:04:23 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T16:04:23 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T16:04:23 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T16:04:23 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T16:04:23 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T16:04:23 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T16:04:23 | INFO | __main__ : Start training
2024-02-29T16:04:25 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T16:06:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:06:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:20:38 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T16:20:38 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T16:20:38 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T16:20:38 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T16:20:38 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T16:20:38 | INFO | __main__ : Creating dataset for pt
2024-02-29T16:20:38 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T16:21:34 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T16:21:34 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T16:21:55 | INFO | tasks.shared_utils : Creating model
2024-02-29T16:21:55 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T16:21:56 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T16:21:56 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T16:21:56 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T16:21:56 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T16:21:56 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T16:21:56 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T16:21:57 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T16:21:57 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T16:21:57 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T16:21:57 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T16:21:57 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T16:21:57 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T16:21:57 | INFO | __main__ : Start training
2024-02-29T16:21:59 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T16:23:57 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:23:57 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:23:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:23:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:23:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:23:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:04 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:04 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:24:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:32:04 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T16:32:04 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T16:32:05 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T16:32:05 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T16:32:05 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T16:32:05 | INFO | __main__ : Creating dataset for pt
2024-02-29T16:32:05 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T16:32:59 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T16:33:00 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T16:33:24 | INFO | tasks.shared_utils : Creating model
2024-02-29T16:33:24 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T16:33:25 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T16:33:25 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T16:33:25 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T16:33:25 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T16:33:25 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T16:33:26 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T16:33:27 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T16:33:27 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T16:33:27 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T16:33:27 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T16:33:27 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T16:33:27 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T16:33:27 | INFO | __main__ : Start training
2024-02-29T16:33:28 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T16:35:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:54 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:54 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:35:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:36:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:36:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:36:04 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:36:04 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:36:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T16:36:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:16:54 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T17:16:54 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T17:16:54 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T17:16:54 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T17:16:54 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T17:16:54 | INFO | __main__ : Creating dataset for pt
2024-02-29T17:16:54 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T17:17:50 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T17:17:50 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T17:28:31 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T17:28:31 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T17:28:31 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T17:28:31 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T17:28:31 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T17:28:31 | INFO | __main__ : Creating dataset for pt
2024-02-29T17:28:31 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T17:29:30 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T17:29:30 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T17:29:48 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T17:29:48 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T17:29:48 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T17:29:48 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T17:29:48 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T17:29:48 | INFO | __main__ : Creating dataset for pt
2024-02-29T17:29:48 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T17:29:59 | INFO | tasks.shared_utils : Creating model
2024-02-29T17:29:59 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T17:30:00 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T17:30:00 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T17:30:00 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T17:30:01 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T17:30:01 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T17:30:01 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T17:30:02 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T17:30:02 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T17:30:02 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T17:30:02 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T17:30:02 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T17:30:02 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T17:30:02 | INFO | __main__ : Start training
2024-02-29T17:30:03 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T17:34:11 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:11 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:20 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:20 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:23 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:23 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:25 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:25 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:34:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:37:43 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T17:37:43 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T17:37:43 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T17:37:43 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T17:37:43 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T17:37:43 | INFO | __main__ : Creating dataset for pt
2024-02-29T17:37:43 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T17:38:38 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T17:38:38 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T17:39:02 | INFO | tasks.shared_utils : Creating model
2024-02-29T17:39:03 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T17:39:03 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T17:39:03 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T17:39:03 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T17:39:03 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T17:39:03 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T17:39:04 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T17:39:06 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T17:39:06 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T17:39:06 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T17:39:06 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T17:39:06 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T17:39:06 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T17:39:06 | INFO | __main__ : Start training
2024-02-29T17:39:07 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T17:41:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:20 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:20 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T17:41:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:30:41 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T18:30:41 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T18:30:42 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T18:30:42 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T18:30:42 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T18:30:42 | INFO | __main__ : Creating dataset for pt
2024-02-29T18:30:42 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T18:31:38 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T18:31:38 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T18:32:00 | INFO | tasks.shared_utils : Creating model
2024-02-29T18:32:00 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T18:32:01 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T18:32:01 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T18:32:01 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T18:32:01 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T18:32:01 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T18:32:02 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T18:32:03 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T18:32:03 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T18:32:03 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T18:32:03 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T18:32:03 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T18:32:03 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T18:32:03 | INFO | __main__ : Start training
2024-02-29T18:32:04 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T18:34:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:06 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:06 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:06 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:06 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:17 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:17 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:34:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T18:59:29 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T18:59:29 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T18:59:30 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T18:59:30 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T18:59:30 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T18:59:30 | INFO | __main__ : Creating dataset for pt
2024-02-29T18:59:30 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T19:00:25 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T19:00:25 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T19:00:47 | INFO | tasks.shared_utils : Creating model
2024-02-29T19:00:47 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T19:00:48 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T19:00:48 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T19:00:48 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T19:00:48 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T19:00:48 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T19:00:49 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T19:00:49 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:49 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T19:00:50 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T19:00:50 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T19:00:50 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T19:00:50 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T19:00:50 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T19:00:50 | INFO | __main__ : Start training
2024-02-29T19:00:51 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T19:02:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:02:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:03:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:03:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:03:08 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T19:03:08 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:50:20 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T21:50:20 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T21:50:20 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T21:50:20 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T21:50:20 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T21:50:20 | INFO | __main__ : Creating dataset for pt
2024-02-29T21:50:20 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T21:51:17 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T21:51:17 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T21:51:40 | INFO | tasks.shared_utils : Creating model
2024-02-29T21:51:40 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T21:51:40 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T21:51:41 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T21:51:41 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T21:51:41 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T21:51:41 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T21:51:41 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T21:51:42 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T21:51:42 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T21:51:42 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T21:51:42 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T21:51:42 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T21:51:42 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T21:51:42 | INFO | __main__ : Start training
2024-02-29T21:51:44 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T21:54:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:36 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:36 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T21:54:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:14:18 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-02-29T23:14:18 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-02-29T23:14:19 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-02-29T23:14:19 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-02-29T23:14:19 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-02-29T23:14:19 | INFO | __main__ : Creating dataset for pt
2024-02-29T23:14:19 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-02-29T23:15:16 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-02-29T23:15:17 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-02-29T23:15:39 | INFO | tasks.shared_utils : Creating model
2024-02-29T23:15:39 | INFO | models.viclip : vision encoder name: vit_b16
2024-02-29T23:15:40 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-02-29T23:15:40 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-02-29T23:15:40 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-02-29T23:15:40 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-02-29T23:15:40 | INFO | models.viclip : text encoder name: vit_b16
2024-02-29T23:15:41 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-02-29T23:15:42 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-02-29T23:15:42 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-02-29T23:15:42 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-02-29T23:15:42 | INFO | tasks.shared_utils : Auto resuming
2024-02-29T23:15:42 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-02-29T23:15:42 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-02-29T23:15:42 | INFO | __main__ : Start training
2024-02-29T23:15:43 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-02-29T23:17:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:49 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:49 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:51 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:17:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:18:00 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-02-29T23:18:00 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:47:21 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T02:47:21 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: likunchang
      project: vindlu_videoclip }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T02:47:21 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T02:47:21 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T02:47:21 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T02:47:21 | INFO | __main__ : Creating dataset for pt
2024-03-01T02:47:21 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T02:48:19 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T02:48:20 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T02:48:42 | INFO | tasks.shared_utils : Creating model
2024-03-01T02:48:42 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T02:48:42 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T02:48:43 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T02:48:43 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T02:48:43 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T02:48:43 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T02:48:43 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T02:48:44 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T02:48:44 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T02:48:44 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T02:48:44 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T02:48:44 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T02:48:44 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T02:48:44 | INFO | __main__ : Start training
2024-03-01T02:48:45 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T02:50:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:49 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:49 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:53 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:56 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:50:56 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:51:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:51:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:51:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T02:51:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T03:43:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-01T03:43:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-01T03:44:58 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2599]  eta: 101 days, 11:01:57  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 6.2085  time: 3372.8811  data: 3247.3279  max mem: 41898 res mem: 46648
2024-03-01T04:38:45 | INFO | utils.basic_utils : Train Epoch: [0]  [  10/2599]  eta: 17 days, 23:27:24  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 4.0844  time: 599.9399  data: 539.3212  max mem: 42889 res mem: 47424
2024-03-01T05:31:17 | INFO | utils.basic_utils : Train Epoch: [0]  [  20/2599]  eta: 13 days, 20:40:24  lr: 0.000003  temperature: 0.0100  video-loss_vtc: 3.3662  time: 318.9504  data: 269.7538  max mem: 42889 res mem: 47424
2024-03-01T06:25:28 | INFO | utils.basic_utils : Train Epoch: [0]  [  30/2599]  eta: 12 days, 11:19:28  lr: 0.000005  temperature: 0.0101  video-loss_vtc: 3.1592  time: 320.1813  data: 260.2700  max mem: 42889 res mem: 47424
2024-03-01T10:41:37 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T10:41:37 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T10:41:37 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T10:41:37 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T10:41:37 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T10:41:37 | INFO | __main__ : Creating dataset for pt
2024-03-01T10:41:37 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T10:42:34 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T10:42:35 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T10:42:58 | INFO | tasks.shared_utils : Creating model
2024-03-01T10:42:58 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T10:42:58 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T10:42:59 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T10:42:59 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T10:42:59 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T10:42:59 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T10:42:59 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T10:43:00 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T10:43:00 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T10:43:00 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T10:43:00 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T10:43:00 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T10:43:00 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T10:43:00 | INFO | __main__ : Start training
2024-03-01T10:43:02 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T10:45:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:05 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:06 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:06 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:16 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:16 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:22 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T10:45:22 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:32:34 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T15:32:34 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T15:32:34 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T15:32:34 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T15:32:34 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T15:32:34 | INFO | __main__ : Creating dataset for pt
2024-03-01T15:32:34 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T15:33:31 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T15:33:31 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T15:33:55 | INFO | tasks.shared_utils : Creating model
2024-03-01T15:33:55 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T15:33:55 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T15:33:56 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T15:33:56 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T15:33:56 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T15:33:56 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T15:33:56 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T15:33:57 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T15:33:57 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T15:33:57 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T15:33:57 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T15:33:57 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T15:33:57 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T15:33:57 | INFO | __main__ : Start training
2024-03-01T15:33:58 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T15:35:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:35:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:35:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:35:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:35:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:35:58 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T15:36:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T18:58:30 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T18:58:30 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T18:58:30 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T18:58:30 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T18:58:30 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T18:58:30 | INFO | __main__ : Creating dataset for pt
2024-03-01T18:58:30 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T18:59:40 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T18:59:41 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T19:00:13 | INFO | tasks.shared_utils : Creating model
2024-03-01T19:00:13 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T19:00:14 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T19:00:15 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T19:00:15 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T19:00:15 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T19:00:15 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T19:00:16 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T19:00:18 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T19:00:18 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T19:00:18 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T19:00:18 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T19:00:18 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T19:00:18 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T19:00:18 | INFO | __main__ : Start training
2024-03-01T19:00:20 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T19:02:57 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:02:57 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:02:57 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:02:57 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:02:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:02:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:01 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:02 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:03:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:30:02 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T19:30:02 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T19:30:02 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T19:30:02 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T19:30:02 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T19:30:02 | INFO | __main__ : Creating dataset for pt
2024-03-01T19:30:02 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T19:30:56 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T19:30:56 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T19:31:19 | INFO | tasks.shared_utils : Creating model
2024-03-01T19:31:19 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T19:31:20 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T19:31:20 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T19:31:20 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T19:31:20 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T19:31:20 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T19:31:21 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T19:31:22 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T19:31:22 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T19:31:22 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T19:31:22 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T19:31:22 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T19:31:22 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T19:31:22 | INFO | __main__ : Start training
2024-03-01T19:31:23 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T19:33:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:39 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:39 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:33:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:48:59 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T19:48:59 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T19:48:59 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T19:48:59 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T19:48:59 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T19:48:59 | INFO | __main__ : Creating dataset for pt
2024-03-01T19:48:59 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T19:50:00 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T19:50:00 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T19:50:22 | INFO | tasks.shared_utils : Creating model
2024-03-01T19:50:23 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T19:50:23 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T19:50:24 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T19:50:24 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T19:50:24 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T19:50:24 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T19:50:24 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T19:50:25 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T19:50:25 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T19:50:25 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T19:50:25 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T19:50:25 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T19:50:25 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T19:50:25 | INFO | __main__ : Start training
2024-03-01T19:50:27 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T19:55:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:14 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:21 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:22 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:22 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:25 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:25 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T19:55:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:21:11 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T20:21:11 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T20:21:11 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T20:21:11 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T20:21:11 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T20:21:11 | INFO | __main__ : Creating dataset for pt
2024-03-01T20:21:11 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T20:22:05 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T20:22:05 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T20:22:27 | INFO | tasks.shared_utils : Creating model
2024-03-01T20:22:27 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T20:22:28 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T20:22:28 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T20:22:28 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T20:22:28 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T20:22:28 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T20:22:29 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T20:22:30 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T20:22:30 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T20:22:30 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T20:22:30 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T20:22:30 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T20:22:30 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T20:22:30 | INFO | __main__ : Start training
2024-03-01T20:22:31 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T20:24:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:40 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:40 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T20:24:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T21:16:56 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-01T21:16:56 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-01T21:18:46 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2599]  eta: 101 days, 12:24:21  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 6.2085  time: 3374.7832  data: 3257.6077  max mem: 41898 res mem: 46648
2024-03-01T22:12:26 | INFO | utils.basic_utils : Train Epoch: [0]  [  10/2599]  eta: 17 days, 23:11:03  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 4.0844  time: 599.5610  data: 543.5663  max mem: 42889 res mem: 47424
2024-03-01T23:04:55 | INFO | utils.basic_utils : Train Epoch: [0]  [  20/2599]  eta: 13 days, 20:24:27  lr: 0.000003  temperature: 0.0100  video-loss_vtc: 3.3662  time: 318.4655  data: 273.2573  max mem: 42889 res mem: 47424
2024-03-01T23:17:59 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T23:17:59 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T23:17:59 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T23:18:00 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T23:18:00 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T23:18:00 | INFO | __main__ : Creating dataset for pt
2024-03-01T23:18:00 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T23:18:57 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T23:18:57 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T23:19:20 | INFO | tasks.shared_utils : Creating model
2024-03-01T23:19:21 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T23:19:21 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T23:19:21 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T23:19:21 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T23:19:22 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T23:19:22 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T23:19:22 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T23:19:23 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T23:19:23 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T23:19:23 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T23:19:23 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T23:19:23 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T23:19:23 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T23:19:23 | INFO | __main__ : Start training
2024-03-01T23:19:24 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T23:21:25 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:21:25 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:21:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:21:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:25:47 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-01T23:25:47 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-01T23:25:48 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-01T23:25:48 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-01T23:25:48 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-01T23:25:48 | INFO | __main__ : Creating dataset for pt
2024-03-01T23:25:48 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-01T23:26:41 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-01T23:26:42 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-01T23:27:04 | INFO | tasks.shared_utils : Creating model
2024-03-01T23:27:04 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-01T23:27:04 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-01T23:27:05 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-01T23:27:05 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-01T23:27:05 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-01T23:27:05 | INFO | models.viclip : text encoder name: vit_b16
2024-03-01T23:27:05 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-01T23:27:06 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-01T23:27:06 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-01T23:27:06 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-01T23:27:06 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-01T23:27:07 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-01T23:27:07 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-01T23:27:07 | INFO | tasks.shared_utils : Auto resuming
2024-03-01T23:27:07 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-01T23:27:07 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-01T23:27:07 | INFO | __main__ : Start training
2024-03-01T23:27:08 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-01T23:29:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:11 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:11 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:13 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:20 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:20 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-01T23:29:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:23:04 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-02T00:23:04 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-02T00:23:04 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-02T00:23:04 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-02T00:23:04 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-02T00:23:04 | INFO | __main__ : Creating dataset for pt
2024-03-02T00:23:04 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-02T00:23:59 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-02T00:24:00 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-02T00:24:22 | INFO | tasks.shared_utils : Creating model
2024-03-02T00:24:22 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-02T00:24:22 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-02T00:24:23 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-02T00:24:23 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-02T00:24:23 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-02T00:24:23 | INFO | models.viclip : text encoder name: vit_b16
2024-03-02T00:24:24 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-02T00:24:25 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-02T00:24:25 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-02T00:24:25 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-02T00:24:25 | INFO | tasks.shared_utils : Auto resuming
2024-03-02T00:24:25 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-02T00:24:25 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-02T00:24:25 | INFO | __main__ : Start training
2024-03-02T00:24:26 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-02T00:26:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:28 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:29 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:33 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:40 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:40 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T00:26:45 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:11:11 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-02T01:11:11 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-02T01:11:11 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-02T01:11:11 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-02T01:11:11 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-02T01:11:11 | INFO | __main__ : Creating dataset for pt
2024-03-02T01:11:11 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-02T01:12:06 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-02T01:12:06 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-02T01:12:27 | INFO | tasks.shared_utils : Creating model
2024-03-02T01:12:28 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-02T01:12:28 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-02T01:12:29 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-02T01:12:29 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-02T01:12:29 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-02T01:12:29 | INFO | models.viclip : text encoder name: vit_b16
2024-03-02T01:12:29 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-02T01:12:31 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-02T01:12:31 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-02T01:12:31 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-02T01:12:31 | INFO | tasks.shared_utils : Auto resuming
2024-03-02T01:12:31 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-02T01:12:31 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-02T01:12:31 | INFO | __main__ : Start training
2024-03-02T01:12:32 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-02T01:14:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:32 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:37 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:42 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:14:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:20:48 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-02T01:20:48 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-02T01:20:48 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-02T01:20:48 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-02T01:20:48 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-02T01:20:48 | INFO | __main__ : Creating dataset for pt
2024-03-02T01:20:48 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-02T01:21:41 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-02T01:21:41 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-02T01:22:03 | INFO | tasks.shared_utils : Creating model
2024-03-02T01:22:03 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-02T01:22:04 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-02T01:22:04 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-02T01:22:04 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-02T01:22:04 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-02T01:22:04 | INFO | models.viclip : text encoder name: vit_b16
2024-03-02T01:22:05 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-02T01:22:06 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-02T01:22:06 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-02T01:22:06 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-02T01:22:06 | INFO | tasks.shared_utils : Auto resuming
2024-03-02T01:22:06 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-02T01:22:06 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-02T01:22:06 | INFO | __main__ : Start training
2024-03-02T01:22:07 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-02T01:24:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:09 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:10 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:12 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:18 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T01:24:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:16:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-02T02:16:19 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-02T02:18:24 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2599]  eta: 101 days, 13:32:16  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 6.2085  time: 3376.3513  data: 3244.5518  max mem: 41898 res mem: 46648
2024-03-02T02:42:20 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-02T02:42:20 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-02T02:42:20 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-02T02:42:20 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-02T02:42:20 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-02T02:42:20 | INFO | __main__ : Creating dataset for pt
2024-03-02T02:42:20 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-02T02:43:16 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-02T02:43:16 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-02T02:43:39 | INFO | tasks.shared_utils : Creating model
2024-03-02T02:43:39 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-02T02:43:39 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-02T02:43:40 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-02T02:43:40 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-02T02:43:40 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-02T02:43:40 | INFO | models.viclip : text encoder name: vit_b16
2024-03-02T02:43:40 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-02T02:43:41 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-02T02:43:41 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-02T02:43:41 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-02T02:43:41 | INFO | tasks.shared_utils : Auto resuming
2024-03-02T02:43:41 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-02T02:43:41 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-02T02:43:41 | INFO | __main__ : Start training
2024-03-02T02:43:43 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-02T02:45:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:47 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:48 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:48 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:50 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:55 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T02:45:59 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T03:38:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-02T03:38:03 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: torch.distributed.reduce_op is deprecated, please use torch.distributed.ReduceOp instead
  builtin_warn(*args, **kwargs)

2024-03-02T03:39:59 | INFO | utils.basic_utils : Train Epoch: [0]  [   0/2599]  eta: 101 days, 13:20:27  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 6.2085  time: 3376.0784  data: 3252.0276  max mem: 41898 res mem: 46648
2024-03-02T04:33:11 | INFO | utils.basic_utils : Train Epoch: [0]  [  10/2599]  eta: 17 days, 21:25:20  lr: 0.000002  temperature: 0.0100  video-loss_vtc: 4.0844  time: 597.1110  data: 543.2846  max mem: 42889 res mem: 47424
2024-03-02T05:26:33 | INFO | utils.basic_utils : Train Epoch: [0]  [  20/2599]  eta: 13 days, 21:17:23  lr: 0.000003  temperature: 0.0100  video-loss_vtc: 3.3662  time: 319.6939  data: 273.6078  max mem: 42889 res mem: 47424
2024-03-02T06:21:19 | INFO | utils.basic_utils : Train Epoch: [0]  [  30/2599]  eta: 12 days, 12:33:38  lr: 0.000005  temperature: 0.0101  video-loss_vtc: 3.1592  time: 324.4222  data: 263.4337  max mem: 42889 res mem: 47424
2024-03-02T08:04:04 | INFO | utils.basic_utils : Train Epoch: [0]  [  40/2599]  eta: 13 days, 21:14:37  lr: 0.000006  temperature: 0.0101  video-loss_vtc: 2.9049  time: 472.5572  data: 382.2767  max mem: 42889 res mem: 47424
2024-03-02T08:59:50 | INFO | utils.basic_utils : Train Epoch: [0]  [  50/2599]  eta: 13 days, 1:18:46  lr: 0.000008  temperature: 0.0101  video-loss_vtc: 2.5072  time: 475.5354  data: 373.5011  max mem: 42889 res mem: 47424
2024-03-02T09:57:03 | INFO | utils.basic_utils : Train Epoch: [0]  [  60/2599]  eta: 12 days, 12:36:35  lr: 0.000009  temperature: 0.0102  video-loss_vtc: 2.6271  time: 338.9436  data: 227.5445  max mem: 42889 res mem: 47424
2024-03-02T10:48:13 | INFO | utils.basic_utils : Train Epoch: [0]  [  70/2599]  eta: 11 days, 23:37:45  lr: 0.000011  temperature: 0.0102  video-loss_vtc: 2.8485  time: 325.1313  data: 212.9469  max mem: 42889 res mem: 47424
2024-03-02T11:30:54 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-02T11:30:54 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-02T11:30:54 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-02T11:30:54 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-02T11:30:54 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-02T11:30:54 | INFO | __main__ : Creating dataset for pt
2024-03-02T11:30:54 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-02T12:32:31 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-02T12:32:31 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-02T12:32:31 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-02T12:32:31 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-02T12:32:31 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-02T12:32:31 | INFO | __main__ : Creating dataset for pt
2024-03-02T12:32:31 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-02T12:33:28 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-02T12:33:29 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-02T12:33:51 | INFO | tasks.shared_utils : Creating model
2024-03-02T12:33:51 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-02T12:33:52 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-02T12:33:52 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-02T12:33:52 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-02T12:33:52 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-02T12:33:52 | INFO | models.viclip : text encoder name: vit_b16
2024-03-02T12:33:52 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-02T12:33:54 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-02T12:33:54 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-02T12:33:54 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-02T12:33:54 | INFO | tasks.shared_utils : Auto resuming
2024-03-02T12:33:54 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-02T12:33:54 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-02T12:33:54 | INFO | __main__ : Start training
2024-03-02T12:33:55 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-02T12:36:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:31 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:35 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:36 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:36 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:38 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:39 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:39 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:43 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:46 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:52 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T12:36:52 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:41:03 | INFO | vindlu : Logging to: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base/train.log
2024-03-02T13:41:03 | INFO | utils.config_utils : config: {
  data_dir: /mnt/petrelfs/share/videointern/annotations
  data_root: /mnt/petrelfs/share/videointern/annotations/videos_images
  anno_root_pt: /mnt/petrelfs/share/videointern/annotations/anno_pretrain
  anno_root_downstream: /mnt/petrelfs/share/videointern/annotations/anno_downstream
  available_corpus: {
      cc3m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']
      cc12m: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']
      sbu: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images']
      vg: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']
      coco: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption']
      imagenet1k: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train']
      webvid: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video']
      webvid_10m: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']
      kinetics400: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics400_train.json', '/mnt/petrelfs/videointern/k400', 'video']
      kinetics710: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']
      kinetics710_raw: ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']
      webvid_dummy: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_dummy.json', 'pssd:s3://WebVid10M', 'video']
      internvid_10m_flt: ['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']
      coco_vg: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images']]
      in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC']]
      webvid_cc3m_in1k_k710: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/imagenet1k_train.json', '/mnt/petrelfs/share/images/train'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_train.json', '', 'video']]
      webvid_cc3m_k710raw: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/kinetics710_raw_train.json', '', 'only_video']]
      webvid_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid12m_14m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      webvid10m_14m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/coco.json', '/mnt/petrelfs/videointern/coco_caption'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/vg.json', '/mnt/petrelfs/videointern/VG/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/sbu.json', '/mnt/petrelfs/videointern/SBU/images'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_17m: [['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/webvid_train.json', 'pssd:s3://WebVid2M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      simple_25m: [['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc3m_train.json', 'pssd:s3://GCC'], ['/mnt/petrelfs/share/videointern/annotations/anno_pretrain/cc12m_train.json', 'pssd:s3://GCC/GCC12m']]
      viclip_20m: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video'], ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_pretrain/webvid_10m_train_clean_230413.json', 'pssd:s3://WebVid10M', 'video']]
      viclip: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video']
      k400_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics400_validate.json', 'pssd:s3://k400/', 'video']
      k600_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics600_validate.json', '', 'video']
      k700_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/kinetics700_validate.json', '', 'video']
      sthsthv1_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv1_validate_clean2.json', '', 'video']
      sthsthv2_act_val: ['/mnt/petrelfs/share_data/liyizhuo/datasets/annotations/anno_downstream/sthsthv2_validate_clean2.json', '', 'video'] }
  VisionEncoders: {
      beit: {
          name: beit_base
          pretrained: microsoft/beit-base-patch16-224-pt22k-ft22k
          d_model: 768 }
      beit_large: {
          name: beit_large
          pretrained: microsoft/beit-large-patch16-224-pt22k-ft22k
          d_model: 1024 } }
  TextEncoders: {
      bert: {
          name: bert_base
          pretrained: bert-base-uncased
          config: configs/config_bert.json
          d_model: 768
          fusion_layer: 9 }
      bert_large: {
          name: bert_large
          pretrained: bert-large-uncased
          config: configs/config_bert_large.json
          d_model: 1024
          fusion_layer: 19 } }
  train_corpus: viclip
  train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
  test_file: {
      msrvtt_1k_test: ['/mnt/petrelfs/share/videointern/annotations/anno_downstream/msrvtt_test1k.json', 'pssd:s3://MSR-VTT/MSRVTT_Videos', 'video'] }
  test_types: ['msrvtt_1k_test']
  num_workers: 8
  stop_key: None
  num_frames: 8
  num_frames_test: 8
  batch_size: 512
  batch_size_test: 64
  max_txt_l: 32
  inputs: {
      image_res: 224
      video_input: {
          num_frames: 8
          sample_type: rand
          num_frames_test: 8
          sample_type_test: middle
          random_aug: False }
      max_txt_l: {
          image: 32
          video: 32 }
      batch_size: {
          image: 512
          video: 512 }
      batch_size_test: {
          image: 64
          video: 64 } }
  model: {
      model_cls: ViCLIP
      vision_encoder: {
          name: vit_b16
          pretrained: CLIP-ViT-B/16
          d_model: 768
          kernel_size: 1
          center: True
          drop_path_rate: 0.1
          masking_prob: 0.9
          checkpoint_num: 0
          dropout: 0.0 }
      text_encoder: {
          pretrained: CLIP-ViT-B/16
          name: vit_b16
          d_model: 512
          vocab_size: 49408 }
      requires_raw_text: True
      embed_dim: 512
      temp: 0.01
      temp_min: 0.01
      freeze_text: True }
  criterion: {
      loss_weight: {
          vtc: 1.0
          cos: 0.0 } }
  optimizer: {
      opt: adamW
      lr: 0.0002
      opt_betas: [0.9, 0.98]
      weight_decay: 0.2
      max_grad_norm: -1
      different_lr: {
          enable: False
          module_names: []
          lr: 0.001 } }
  scheduler: {
      sched: cosine
      epochs: 10
      min_lr_multi: 0.01
      warmup_epochs: 0.5 }
  evaluate: False
  deep_fusion: False
  evaluation: {
      eval_frame_ensemble: concat
      eval_x_only: False
      k_test: 128
      eval_offload: True }
  fp16: True
  gradient_checkpointing: True
  wandb: {
      enable: False
      entity: OpenGVLab
      project: ViCLIP }
  dist_url: env://
  device: cuda
  mode: pt
  output_dir: exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
  resume: False
  debug: False
  log_freq: 10
  seed: 42
  save_latest: False
  auto_resume: True
  pretrained_path: 
  deepspeed: {
      enable: False
      stage: 2 }
  rank: 0
  world_size: 8
  gpu: 0
  distributed: True
  dist_backend: nccl }
2024-03-02T13:41:03 | INFO | torch.distributed.distributed_c10d : Added key: store_based_barrier_key:2 to store for rank: 0
2024-03-02T13:41:03 | INFO | torch.distributed.distributed_c10d : Rank 0: Completed store-based barrier for key:store_based_barrier_key:2 with 8 nodes.
2024-03-02T13:41:03 | INFO | __main__ : train_file: [['phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json', '', 'video']]
2024-03-02T13:41:03 | INFO | __main__ : Creating dataset for pt
2024-03-02T13:41:03 | INFO | dataset.sqlite_dataset : Loading json file phdd:s3://video_caption_summarized_list/resized_0613_filtered_30p_10m.json
2024-03-02T13:42:03 | INFO | dataset.sqlite_dataset : Num samples: 10647458
2024-03-02T13:42:03 | INFO | dataset.sqlite_dataset : Num samples too short: 0
2024-03-02T13:42:27 | INFO | tasks.shared_utils : Creating model
2024-03-02T13:42:27 | INFO | models.viclip : vision encoder name: vit_b16
2024-03-02T13:42:28 | INFO | models.backbones.clip.clip_vision : load pretrained weights from CLIP-ViT-B/16
2024-03-02T13:42:28 | INFO | models.backbones.clip.clip_vision : Inflate: conv1.weight, torch.Size([768, 3, 16, 16]) => torch.Size([768, 3, 1, 16, 16])
2024-03-02T13:42:28 | INFO | models.backbones.clip.clip_vision : Init center: True
2024-03-02T13:42:29 | INFO | models.backbones.clip.clip_vision : Load pretrained weights: _IncompatibleKeys(missing_keys=['temporal_positional_embedding'], unexpected_keys=[])
2024-03-02T13:42:29 | INFO | models.viclip : text encoder name: vit_b16
2024-03-02T13:42:29 | INFO | models.backbones.clip.clip_text : Load pretrained weights from /mnt/petrelfs/share_data/likunchang/model/clip_text_encoder/vit_b16_text.pth
2024-03-02T13:42:30 | INFO | utils.optimizer : diff_names: [], diff_lr: None
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.temp: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.class_embedding: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.positional_embedding: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.temporal_positional_embedding: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.proj: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.conv1.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.ln_pre.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.0.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.1.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:30 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.2.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.3.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.4.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.5.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.6.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.7.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.8.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.9.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.10.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.in_proj_bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.attn.out_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_1.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_fc.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.weight: wd: 0.2, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.mlp.c_proj.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.transformer.resblocks.11.ln_2.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.ln_post.weight: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : param module.vision_encoder.ln_post.bias: wd: 0, lr: 0.0002
2024-03-02T13:42:31 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0 len(p)=104
2024-03-02T13:42:31 | INFO | utils.optimizer : optimizer -- lr=0.0002 wd=0.2 len(p)=50
2024-03-02T13:42:31 | INFO | tasks.shared_utils : Auto resuming
2024-03-02T13:42:31 | INFO | tasks.shared_utils : Not found checkpoint in exp/exp_pretrain_ViCLIP/viclip_base/viclip_base
2024-03-02T13:42:31 | WARNING | tasks.shared_utils : No pretrained checkpoint provided, training from scratch
2024-03-02T13:42:31 | INFO | __main__ : Start training
2024-03-02T13:42:32 | INFO | dataset.dataloader : MetaLoader has 1 dataloaders, 2599 batches in total
dataloader index=0 name=video, batch-size=512 length(#batches)=2599 
2024-03-02T13:45:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:15 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:17 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:17 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:22 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:22 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:24 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:26 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:27 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:30 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

2024-03-02T13:45:44 | WARNING | py.warnings : /mnt/petrelfs/heyinan/exps/ViCLIP/utils/distributed.py:21: UserWarning: The default value of the antialias parameter of all the resizing transforms (Resize(), RandomResizedCrop(), etc.) will change from None to True in v0.17, in order to be consistent across the PIL and Tensor backends. To suppress this warning, directly pass antialias=True (recommended, future default), antialias=None (current default, which means False for Tensors and True for PIL), or antialias=False (only works on Tensors - PIL will still use antialiasing). This also applies if you are using the inference transforms from the models weights: update the call to weights.transforms(antialias=True).
  builtin_warn(*args, **kwargs)

